# LR Setting
- BERT: 推荐学习率为 2e-5 或 3e-5，大多数任务可以使用这两个学习率的其中之一进行微调。
- RoBERTa: 推荐学习率为 1e-5 到 5e-5，可以尝试 1e-5 作为起始学习率。
- ALBERT: 推荐学习率与 BERT 相似，一般为 1e-5 到 2e-5。
- DeBERTa: 推荐学习率为 2e-5 到 3e-5。
- Electra: 推荐使用较低的学习率，例如 5e-5 到 1e-4，Electra 比 BERT 更高效，所以需要稍高一点的学习率。

# Models
- RoBERTa: 移除nsp只保留mlm，更多训练数据，更大的的batch_size，更长的训练时间，动态masking提高泛化能力
- ALBERT: 引入了跨层的参数共享机制（在所有 Transformer 层中共享权重，而不是为每层独立设置不同的权重），分解的词嵌入矩阵，将nsp变为sop
- DeBERTa: 解耦的注意力机制将词的内容（词语的语义）和位置（词在句子中的位置）进行分离，相对位置编码
- Electra: 让模型识别哪些词是被替换过的，Electra 先训练一个生成器模型来替换一些单词，然后训练一个鉴别器模型（Electra 本身）来判断句子中哪些词是被替换的（GAN）。

# Twitter US Airline Sentiment, pretrained model
分别为：给定标签，给定标签优化，未给定标签
- Labels: positive/1, negative/0, neutral/2

- 无文本预处理, average='macro', 有mismatch问题

|   Model    |   Original(Acc/Prec/Rec/F1)   |  Rewritten(Acc/Prec/Rec/F1)   |  LR  |
|:----------:|:-----------------------------:|:-----------------------------:|:----:|
|   `BERT`   | 85.48 / 81.27 / 80.62 / 80.94 | 76.98 / 73.44 / 66.05 / 68.62 | 2e-5 |
| `RoBERTa ` | 86.13 / 81.59 / 80.72 / 80.86 | 79.13 / 74.91 / 72.87 / 73.30 | 1e-5 |
|  `ALBERT`  | 85.35 / 81.49 / 79.28 / 80.32 | 77.25 / 72.56 / 68.90 / 70.07 | 1e-5 |
| `DeBERTa`  | 85.83 / 81.34 / 80.96 / 81.15 | 77.66 / 72.85 / 68.07 / 69.92 | 2e-5 |

- 含文本预处理, average='macro', 有mismatch问题

|   Model    |   Original(Acc/Prec/Rec/F1)   |  Rewritten(Acc/Prec/Rec/F1)   |  LR  |
|:----------:|:-----------------------------:|:-----------------------------:|:----:|
|   `BERT`   | 84.80 / 80.40 / 77.87 / 78.89 | 78.65 / 72.45 / 74.37 / 73.25 | 2e-5 |
| `RoBERTa ` | 84.05 / 77.73 / 79.51 / 77.58 | 80.98 / 74.59 / 75.61 / 75.05 | 1e-5 |
|  `ALBERT`  | 83.67 / 78.11 / 79.21 / 78.64 | 76.91 / 73.28 / 68.41 / 69.80 | 1e-5 |
| `DeBERTa`  | 84.80 / 79.00 / 80.08 / 79.34 | 80.57 / 75.22 / 75.30 / 75.15 | 2e-5 |

### NEW PROMPT
- 无文本预处理, average='macro', 有mismatch问题

|   Model    |   Original(Acc/Prec/Rec/F1)   |  Rewritten(Acc/Prec/Rec/F1)   |  LR  |
|:----------:|:-----------------------------:|:-----------------------------:|:----:|
|   `BERT`   | 84.80 / 79.87 / 78.92 / 79.31 | 78.28 / 71.23 / 71.04 / 71.11 | 2e-5 |
| `RoBERTa ` | 86.17 / 82.57 / 79.16 / 80.72 | 79.23 / 71.53 / 72.87 / 72.12 | 1e-5 |
|  `ALBERT`  | 82.41 / 77.12 / 76.74 / 76.91 | 79.03 / 73.03 / 69.72 / 71.19 | 1e-5 |
| `DeBERTa`  | 86.20 / 82.07 / 80.16 / 81.05 | 80.29 / 73.65 / 72.35 / 72.96 | 2e-5 |

### task known
- 无文本预处理, average='weighted'

  |   Model    |   Original(Acc/Prec/Rec/F1)   |  Rewritten(Acc/Prec/Rec/F1)   |  LR  |
  |:----------:|:-----------------------------:|:-----------------------------:|:----:|
  |   `BERT`   | 84.80 / 84.48 / 84.80 / 84.58 |                               | 2e-5 |
  | `RoBERTa ` | 86.71 / 86.63 / 86.71 / 86.65 |                               | 1e-5 |
  |  `ALBERT`  | 82.41 / 82.48 / 82.41 / 82.44 |                               | 1e-5 |
  | `DeBERTa`  | 86.65 / 86.50 / 86.65 / 86.29 | 86.37 / 86.16 / 86.37 / 86.24 | 2e-5 |

### Self-reflection
- 无文本预处理, average='weighted', 4o

  |   Model    |     Original(Acc/Prec/Rec/F1)     |    Rewritten(Acc/Prec/Rec/F1)     |  LR  |
  |:----------:|:---------------------------------:|:---------------------------------:|:----:|
  |   `BERT`   |   84.80 / 84.48 / 84.80 / 84.58   |   85.59 / 85.55 / 85.59 / 85.56   | 2e-5 |
  | `RoBERTa ` |   86.17 / 85.74 / 86.17 / 85.84   |   86.61 / 86.32 / 86.61 / 86.35   | 1e-5 |
  |  `ALBERT`  | **82.41 / 82.48 / 82.41 / 82.44** | **85.55 / 85.13 / 85.55 / 85.13** | 1e-5 |
  | `DeBERTa`  |   86.20 / 85.87 / 86.20 / 85.99   |   86.51 / 86.18 / 86.51 / 86.25   | 2e-5 |
  |  `XLNet`   |   85.93 / 85.78 / 85.93 / 85.81   |   86.65 / 86.33 / 86.65 / 86.44   | 2e-5 |
  | `Electra`  |   85.52 / 85.14 / 85.52 / 85.27   |   86.20 / 85.86 / 86.20 / 85.95   | 5e-5 |

## Airline(BERT)分析
- neutral为原始标签的判定为难样本，在不正确预测上占有比原数据更高的比例
- 其他对比在IV中（重点关注），发现positive占比增加：对positive标签的分类能力不如negative

- 信息论 两个句子之间的关系的信息量-对应哪些成分能够最大限度地保留，distribution?
- 两个句子间的相似度量化，两组句子间的量化
- ~~计算两个句子中共同词汇的熵~~，或者分析它们的条件熵，来评估它们之间的信息共享程度
- 训练集的拼接-ML, mismatch?
- 模型提升：提示词/任务 再和前两个结合
- 量化?

# Twitter US Airline Sentiment, RNN
- Labels: positive, negative, neutral

- upper limit, 无文本预处理

|  Model   | Acc(Original) | Acc(Rewritten) |  LR  |
|:--------:|:-------------:|:--------------:|:----:|
|  `RNN`   |     61.84     |     61.84      | 1e-3 |
| `BiRNN`  |     61.84     |     61.84      | 1e-3 |
|  `LSTM`  |     61.84     |     61.84      | 1e-3 |
| `BiLSTM` |     61.84     |     61.84      | 1e-3 |
|  `GRU`   |     61.84     |     61.84      | 1e-3 |
| `BiGRU`  |     61.84     |     61.84      | 1e-3 |

- upper limit, 含文本预处理

|  Model   | Acc(Original) | Acc(Rewritten) |  LR  |
|:--------:|:-------------:|:--------------:|:----:|
|  `RNN`   |     61.84     |     61.84      | 1e-3 |
| `BiRNN`  |     61.84     |     61.84      | 1e-3 |
|  `LSTM`  |     61.84     |     61.84      | 1e-3 |
| `BiLSTM` |     61.84     |     61.84      | 1e-3 |
|  `GRU`   |     61.84     |     61.84      | 1e-3 |
| `BiGRU`  |     61.84     |     61.84      | 1e-3 |

# rte3 given no label domain
- 无文本预处理

|   Model    |   Original(Acc/Prec/Rec/F1)   |    Rewritten(Acc/Prec/Rec/F1) |  LR  |
|:----------:|:-----------------------------:|------------------------------:|:----:|
|   `BERT`   | 55.96 / 72.71 / 53.47 / 42.24 | 56.32 / 68.02 / 53.93 / 43.98 | 2e-5 |
| `RoBERTa ` | 76.90 / 76.89 / 76.71 / 76.76 | 74.01 / 74.25 / 73.62 / 73.68 | 1e-5 |
|  `ALBERT`  | 52.71 / 51.81 / 51.37 / 48.86 | 67.87 / 68.08 / 67.36 / 67.32 | 1e-5 |
| `DeBERTa`  | 66.06 / 66.22 / 65.53 / 65.45 | 70.76 / 71.01 / 70.30 / 70.31 | 2e-5 |
| `Electra`  | 77.62 / 77.68 / 77.75 / 77.61 | 72.20 / 72.19 / 72.26 / 72.18 | 5e-5 |

# rte3 given task and label domain
- 无文本预处理

|   Model    | Original(Acc/Prec/Rec/F1) | Rewritten(Acc/Prec/Rec/F1) |  LR  |
|:----------:|:-------------------------:|:--------------------------:|:----:|
|   `BERT`   |                           |                            | 2e-5 |
| `RoBERTa ` |                           |                            | 1e-5 |
|  `ALBERT`  |                           |                            | 1e-5 |
| `DeBERTa`  |                           |                            | 2e-5 |
| `Electra`  |                           |                            | 5e-5 |

# mrpc given no label domain
- 无文本预处理

|   Model    | Original(Acc/Prec/Rec/F1) | Rewritten(Acc/Prec/Rec/F1) |  LR  |
|:----------:|:-------------------------:|:--------------------------:|:----:|
|   `BERT`   |                           |                            | 2e-5 |
| `RoBERTa ` |                           |                            | 1e-5 |
|  `ALBERT`  |                           |                            | 1e-5 |
| `DeBERTa`  |                           |                            | 2e-5 |
| `Electra`  |                           |                            | 5e-5 |

# mrpc given task and label domain
- 无文本预处理

|   Model    | Original(Acc/Prec/Rec/F1) | Rewritten(Acc/Prec/Rec/F1) |  LR  |
|:----------:|:-------------------------:|:--------------------------:|:----:|
|   `BERT`   |                           |                            | 2e-5 |
| `RoBERTa ` |                           |                            | 1e-5 |
|  `ALBERT`  |                           |                            | 1e-5 |
| `DeBERTa`  |                           |                            | 2e-5 |
| `Electra`  |                           |                            | 5e-5 |

# RTE（分别改写两句话，主程序里 1-1）
- Determine if the second sentence can be deduced from the first sentence

|   Model   |         Acc(Original)         |        Acc(Rewritten)         |  LR  |
|:---------:|:-----------------------------:|:-----------------------------:|:----:|
|  `BERT`   | 54.87 / 55.23 / 54.51 [54.87] | 57.40 / 56.32 / 55.23 [56.31] | 2e-5 |
| `RoBERTa` |     79.06 / 79.06 / 79.06     |         78.70 / 78.70         | 1e-5 |
| `ALBERT`  |         65.70 / 65.70         |         55.96 / 55.96         | 1e-5 |
| `DeBERTa` |         76.90 / 76.90         |         81.23 / 81.23         | 2e-5 |
| `Electra` |         81.23 / 81.23         |         80.14 / 80.14         | 5e-5 |

# RTE（同时改写两句话，明确解释标签 2）
- Determine if the second sentence can be deduced from the first sentence

|   Model   |         Acc(Original)         |        Acc(Rewritten)         |  LR  |
|:---------:|:-----------------------------:|:-----------------------------:|:----:|
|  `BERT`   | 54.15 / 56.68 / 56.32 [55.72] | 56.32 / 54.87 / 53.79 [55.00] | 2e-5 |
| `RoBERTa` |         79.06 / 79.06         |         68.95 / 68.95         | 1e-5 |

# MRPC（同时改写两句话）
- Determine the consistency of the two sentences

|   Model   |         Acc(Original)         |        Acc(Rewritten)         |  LR  |
|:---------:|:-----------------------------:|:-----------------------------:|:----:|
|  `BERT`   | 73.95 / 79.93 / 74.80 [76.23] | 76.88 / 76.88 / 76.88 [76.88] | 2e-5 |
| `RoBERTa` |         87.80 / 87.80         |         86.27 / 86.27         | 1e-5 |
| `ALBERT`  |         81.45 / 81.45         |         78.40 / 78.40         | 1e-5 |
| `DeBERTa` |         85.85 / 85.85         |         87.68 / 87.68         | 2e-5 |
| `Electra` |         84.20 / 84.20         |         84.99 / 84.99         | 5e-5 |  
 