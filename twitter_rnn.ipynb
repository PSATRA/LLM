{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Twitter US Airline Sentiment\n",
    "Analyze how travelers in February 2015 expressed their feelings on Twitter: A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February 2015 and contributors were asked to first classify **positive**, **negative**, and **neutral** tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\")."
   ],
   "id": "4e110c8b5d353daf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:50:33.809721Z",
     "start_time": "2024-10-11T07:50:33.583073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model = \"rnn\"\n",
    "bidirectional = False\n",
    "bool_rewrite = 0\n",
    "pre_processing = 0\n",
    "cuda_NO = 'cuda:0'\n",
    "rand_seed = 18\n",
    "\n",
    "# 部分超参数\n",
    "num_epoch = 5\n",
    "lr = 1e-3\n",
    "dropout = 0\n",
    "n_layers = 5\n",
    "vocab_size = 20000\n",
    "\n",
    "if bool_rewrite == 0:\n",
    "    model_save_path = 'model/rnn.pth'\n",
    "else:\n",
    "    model_save_path = 'model/rnn-rewrite.pth'\n",
    "\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device = f\"{cuda_NO}\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ],
   "id": "7b2e5c3e335841f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 11 15:50:33 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.90                 Driver Version: 565.90         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   51C    P8              3W /   92W |     832MiB /   6141MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3032    C+G   C:\\Windows\\System32\\dwm.exe                 N/A      |\n",
      "|    0   N/A  N/A      5184    C+G   ...B\\system_tray\\lghub_system_tray.exe      N/A      |\n",
      "|    0   N/A  N/A      5968    C+G   ...x64__qmba6cd70vzyy\\ArmouryCrate.exe      N/A      |\n",
      "|    0   N/A  N/A      9264    C+G   ...Style\\12.8.5.8628\\WebView2Ready.exe      N/A      |\n",
      "|    0   N/A  N/A     11372    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     11700    C+G   ...\\PyCharm 2024.1.4\\bin\\pycharm64.exe      N/A      |\n",
      "|    0   N/A  N/A     11884    C+G   ...on\\129.0.2792.79\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     12660    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     15032    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     16440    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     17432    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     17508    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     17656    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     21036    C+G   ...on\\wallpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A     22396    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     24496    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     24920    C+G   ...isty\\CefSharp.BrowserSubprocess.exe      N/A      |\n",
      "|    0   N/A  N/A     27452    C+G   ...e Stream\\98.0.0.0\\GoogleDriveFS.exe      N/A      |\n",
      "|    0   N/A  N/A     28444    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     31188    C+G   ...5\\extracted\\runtime\\WeChatAppEx.exe      N/A      |\n",
      "|    0   N/A  N/A     31392      C   ...nda\\envs\\pytorch-gpu-env\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set Random Seed",
   "id": "3bb37f8d63bd7f0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:50:33.823468Z",
     "start_time": "2024-10-11T07:50:33.810417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(rand_seed)"
   ],
   "id": "d35c1a99e067001c",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokenization & Processing ",
   "id": "fb79c1ddafbee98f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:50:33.838349Z",
     "start_time": "2024-10-11T07:50:33.824049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def tokenizer(text):\n",
    "    vectorizer = CountVectorizer(max_features=vocab_size) # initialize class CountVectorizer\n",
    "    return vectorizer.fit_transform(text).toarray()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str): return \"\" # Check if text is a string\n",
    "    text = text.lower() # Lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n",
    "    text = re.sub(r'\\@\\w+|\\#','', text) # Remove user @ references and '#' from hashtags\n",
    "    text = re.sub(r'\\W', ' ', text) # Remove special characters, numbers, and punctuations\n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text) # Remove single characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # Remove multiple spaces\n",
    "    return text.strip()"
   ],
   "id": "e08de6a2af171424",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Read Data",
   "id": "2e25ce6d99ff20b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:50:35.132529Z",
     "start_time": "2024-10-11T07:50:33.838349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_data = pd.read_csv('DS/Twitter-US-Airline-Sentiment/Tweets_rewrite.csv', sep=',', header=0)\n",
    "if pre_processing:\n",
    "    train_data['Clean-Text'] = train_data['Text'].apply(preprocess_text)\n",
    "    train_data['Clean-Text-Rewrite'] = train_data['Text-Rewrite'].apply(preprocess_text)\n",
    "else:\n",
    "    train_data['Clean-Text'] = train_data['Text']\n",
    "    train_data['Clean-Text-Rewrite'] = train_data['Text-Rewrite']\n",
    "text_column = 'Clean-Text-Rewrite' if bool_rewrite else 'Clean-Text'\n",
    "\n",
    "X = tokenizer(train_data[text_column])\n",
    "y = train_data['Original_Label']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=rand_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=rand_seed)\n",
    "\n",
    "# post-padding\n",
    "X_train = pad_sequences(X_train, maxlen=50, padding='post')\n",
    "X_val = pad_sequences(X_val, maxlen=50, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=50, padding='post')\n",
    "\n",
    "# map labels to integer\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ],
   "id": "989c5ba9992a010b",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset and Dataloader",
   "id": "55bf77bf0e49bc9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:50:35.146607Z",
     "start_time": "2024-10-11T07:50:35.132529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class Airline_Dataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'text': torch.tensor(self.texts[idx], dtype=torch.long),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = Airline_Dataset(X_train, y_train)\n",
    "val_dataset = Airline_Dataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "64eb068976a28dd5",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "944b302f6361ca55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:50:35.160358Z",
     "start_time": "2024-10-11T07:50:35.146607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Sentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout=dropout):\n",
    "        super(Sentiment, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        if base_model == \"rnn\":\n",
    "            self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        elif base_model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        elif base_model == \"gru\":\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid base model\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        _, hidden = self.rnn(embedded)\n",
    "\n",
    "        if isinstance(hidden, tuple):  # recognize LSTM\n",
    "            hidden = hidden[0]\n",
    "        \n",
    "        if bidirectional:\n",
    "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1]\n",
    "            \n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ],
   "id": "4daf5fe531a94220",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "ecfb80e2c270a6eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:50:41.549186Z",
     "start_time": "2024-10-11T07:50:35.160358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch, gc\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Hyper\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "output_dim = len(label_encoder.classes_)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = Sentiment(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "total_steps = len(train_loader) * num_epoch\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epoch=num_epoch):\n",
    "    model.to(device)\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(train_loader):\n",
    "            texts = batch['text'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader):\n",
    "                texts = batch['text'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                outputs = model(texts)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "        val_accuracy = correct / total\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}')\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f'Saved best model with accuracy: {best_accuracy}')\n",
    "            \n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epoch)"
   ],
   "id": "472fc2c171258f74",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:01<00:00, 242.36it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 1081.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.9842878734804893, Val Loss: 0.9331051979375922\n",
      "Saved best model with accuracy: 0.6352459016393442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:01<00:00, 310.08it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 1012.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.9540028897790961, Val Loss: 0.9207716843356257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:01<00:00, 340.02it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 1078.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.9446497005843074, Val Loss: 0.9054968512576559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:01<00:00, 329.27it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 1021.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.9275026155299828, Val Loss: 0.9024962990180306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:01<00:00, 321.19it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 1012.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.9183930997314349, Val Loss: 0.9021276831626892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prediction",
   "id": "7f63f396572d1f56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:50:42.712082Z",
     "start_time": "2024-10-11T07:50:41.549186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = Sentiment(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "model.load_state_dict(torch.load(model_save_path, weights_only=True))\n",
    "\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            texts = batch['text']\n",
    "            labels = batch['label']\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Test Loss: {test_loss / len(test_loader)}')\n",
    "    print(f'Test Accuracy: {accuracy * 100:.9f}%')\n",
    "    \n",
    "test_dataset = Airline_Dataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "test_model(model, test_loader, criterion)"
   ],
   "id": "22ecae0509a62b66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.962230411560639\n",
      "Test Accuracy: 61.843003413%\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
